# Review Question 1.1.2

by Qiang Gao, updated at Mar 20, 2017

## Chapter 1 Finite-Sample Properties of OLS

### Section 1 The Classical Linear Regression Model

...

#### Review Question 1.1.2 \(Conditional cross-moment of error terms\)

Prove the last equality in \(1.1.15\),

$$
\mathrm{E} (\varepsilon_i \varepsilon_j \mid \mathbf{X})
=
\mathrm{E} (\varepsilon_i \mid \mathbf{x}_i)
\mathrm{E} (\varepsilon_j \mid \mathbf{x}_j)
\qquad
\text{(for $i \neq j$)}.
\tag{1.1.15}
$$

**Solution**

$$
\begin{align}
\mathrm{E} ( \varepsilon_i \varepsilon_j \mid \mathbf{X} )
& =
\mathrm{E} [ \mathrm{E} ( \varepsilon_i \varepsilon_j \mid \mathbf{X}, \varepsilon_j ) \mid \mathbf{X} ]
&&
\text{(law of iterated expectations)}
\\ 
& = \mathrm{E} [ \varepsilon_j \mathrm{E} ( \varepsilon_i \mid \mathbf{X}, \varepsilon_j ) \mid \mathbf{X} ]
&&
\text{($\varepsilon_j$ is constant under condition)}
\\
& = \mathrm{E} [ \varepsilon_j \mathrm{E} ( \varepsilon_i \mid \mathbf{x}_i ) \mid \mathbf{X} ]
&&
\text{(random sample)} \\
& = \mathrm{E} ( \varepsilon_i \mid \mathbf{x}_i ) \mathrm{E} ( \varepsilon_j \mid \mathbf{X})
&&
\text{($\mathbf{x}_i$ is known conditional on $\mathbf{X}$)} \\
& = \mathrm{E} ( \varepsilon_i \mid \mathbf{x}_i ) \mathrm{E} ( \varepsilon_j \mid \mathbf{x}_j)
&&
\text{(random sample)}
\end{align}
$$

Copyright Â©2017 by Qiang Gao

