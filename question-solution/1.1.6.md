# Solution to Review Question

by Qiang Gao, updated at Mar 13, 2017

---

## Chapter 1 Finite-Sample Properties of OLS

### Section 1 The Classical Linear Regression Model

...

#### Review Question 1.1.6 (An exercise in conditional and unconditional expectations)

Show that Assumptions 1.2 and 1.4 imply


begin{align}
mathrm{Var} ( \varepsilon_i ) & = \sigma^2
&&
(i = 1, 2, \ldots, n)

text{and} \qquad
mathrm{Cov} ( \varepsilon_i, \varepsilon_j ) & = 0
&&
(i \neq j; i, j = 1, 2, \ldots, n).  \tag{$\ast$}
end{align}


##### Solution

Strict exogeneity implies $$ \mathrm{E} (\varepsilon_i) = 0 $$. So $$ (\ast) $$ is equivalent to

$$
\begin{align}
\mathrm{E} ( \varepsilon_i^2 ) & = \sigma^2
&&
(i = 1, 2, \ldots, n)
\\
\text{and} \qquad
\mathrm{E} ( \varepsilon_i \varepsilon_j ) & = 0
&&
(i \neq j; i, j = 1, 2, \ldots, n).
\end{align}
$$

(1) For $$i = 1, 2, \ldots, n$$,

$$
\begin{align}
\mathrm{E} (\varepsilon_i^2)
& =
\mathrm{E} [\mathrm{E} (\varepsilon_i^2 \mid \mathbf{X})]
&&
\text{(law of total expectations)}
\\ & =
\sigma^2.
&&
\text{(Assumption 1.4)}
\end{align}
$$

(2) For $$i \neq j; i, j = 1, 2, \ldots, n$$,

$$
\begin{align}
\mathrm{E} (\varepsilon_i \varepsilon_j)
& =
\mathrm{E} [ \mathrm{E} (\varepsilon_i \varepsilon_j \mid \mathbf{X}) ]
&&
\text{(law of total expectations)}
\\ & = 0.
&&
\text{(Assumption 1.4)}
\end{align}
$$

---

Copyright Â©2017 by Qiang Gao
